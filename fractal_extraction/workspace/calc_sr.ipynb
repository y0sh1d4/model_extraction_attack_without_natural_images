{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate success rate in victim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hydra\n",
    "import mlflow\n",
    "from omegaconf import DictConfig\n",
    "import foolbox\n",
    "\n",
    "import mlflow_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=\"conf\"):\n",
    "    cfg = hydra.compose(\n",
    "        config_name='config',\n",
    "        overrides=[\n",
    "            \"victim=mnist\",\n",
    "            \"victim.model=medium\"\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_AEs(model, ds_test, attack_method, epsilons):\n",
    "    sm = foolbox.TensorFlowModel(model, bounds=(0, 1))\n",
    "    res = {'raw': [], 'clipped': [], 'is_adv': [], 'label': []}\n",
    "    # Create AEs\n",
    "    for batch in ds_test:\n",
    "        _, clipped, is_adv = attack_method(sm, batch[0],\n",
    "                                           batch[1], epsilons=epsilons)\n",
    "        res['raw'].append([batch[0]]*len(epsilons))\n",
    "        res['clipped'].append(clipped)\n",
    "        res['is_adv'].append(is_adv)\n",
    "        res['label'].append([batch[1]]*len(epsilons))\n",
    "\n",
    "    # Aggregate\n",
    "    result = []\n",
    "    for i in range(len(epsilons)):\n",
    "        tmp = {}\n",
    "        for k in res.keys():\n",
    "            tmp[k] = np.concatenate(\n",
    "                [res[k][v][i].numpy() for v in range(len(res[k]))], axis=0)\n",
    "        result.append(tmp)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Victim modelが正解できるサンプルだけを抽出する\n",
    "def dataset_screening(\n",
    "    victim_model: tf.keras.Model,\n",
    "    dataset: tf.data.Dataset\n",
    ") -> tf.data.Dataset:\n",
    "\n",
    "    correct_x = []\n",
    "    correct_t = []\n",
    "    for batch in dataset:\n",
    "        x, t = batch\n",
    "        t = t.numpy()\n",
    "        y = np.argmax(victim_model(x, training=False).numpy(), axis=1)\n",
    "        idx = (t == y)\n",
    "        correct_x.append(x.numpy()[idx])\n",
    "        correct_t.append(t[idx])\n",
    "    correct_x = np.concatenate(correct_x, axis=0)\n",
    "    correct_t = np.concatenate(correct_t, axis=0)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((correct_x, correct_t))\n",
    "\n",
    "\n",
    "def eval_AEs(victim_model, AEs):\n",
    "    y = []\n",
    "    for batch in AEs:\n",
    "        y.append(victim_model(batch[0], training=False).numpy())\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test dataset\n",
    "get_dataset = getattr(\n",
    "        importlib.import_module(\n",
    "            'datasets.'+cfg['victim']['task_type']\n",
    "        ),\n",
    "        'get_dataset'\n",
    "    )\n",
    "_, ds_test = get_dataset(cfg['victim'])\n",
    "\n",
    "# Load Victim model\n",
    "victim_model = getattr(\n",
    "        importlib.import_module(\n",
    "            'models.'+cfg['victim']['task_type']\n",
    "        ),\n",
    "        cfg['victim']['model']\n",
    "    )()\n",
    "victim_model.load_weights(os.path.join(\n",
    "        cfg['global_params']['victim_model_path'],\n",
    "        cfg['victim']['model']+'.h5'\n",
    "    ))\n",
    "\n",
    "# Datasetのスクリーニング\n",
    "ds_test = dataset_screening(\n",
    "    victim_model,\n",
    "    ds_test\n",
    ")\n",
    "\n",
    "if len(ds_test) < cfg['create_AEs']['num_samples']:\n",
    "    print(\"# of candidates for AEs is lower than create_AEs.num_samples\")\n",
    "\n",
    "ds_test = ds_test.take(\n",
    "    cfg['create_AEs']['num_samples']\n",
    "    ).batch(\n",
    "        cfg['create_AEs']['batch_size']\n",
    "    )\n",
    "\n",
    "# AEs生成\n",
    "eps = [eval(v) for v in cfg['create_AEs']['epsilons']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_method = foolbox.attacks.PGD(\n",
    "    abs_stepsize=1/255.0, random_start=True)\n",
    "result = create_AEs(victim_model, ds_test, attack_method, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/255.0 1.800\n",
      "8/255.0 6.440\n",
      "16/255.0 40.020\n",
      "24/255.0 84.560\n"
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(cfg['create_AEs']['epsilons']):\n",
    "    print(e, f'{np.mean(result[i][\"is_adv\"])*100.0:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i, e in enumerate(cfg['create_AEs']['epsilons']):\n",
    "    tmp = result[i]\n",
    "    pre = []\n",
    "    for x in tmp['clipped']:\n",
    "        p = victim_model(x[np.newaxis, ...], training=False).numpy()\n",
    "        pre.append(p)\n",
    "    tmp['victim_prediction'] = np.concatenate(pre, axis=0)\n",
    "    res[e] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'./figures/ae_origin_{cfg[\"victim\"][\"task_name\"]}.pkl', 'wb') as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
